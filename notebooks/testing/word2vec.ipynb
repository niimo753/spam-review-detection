{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local import\n",
    "import sys\n",
    "if \"../../\" not in sys.path:\n",
    "    sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "# for preprocessing\n",
    "from src.preprocessing import BasicTextCleaning\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# for modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of OFS:  (40432, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I had read some reviews saying that this bra r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I wasn't sure exactly what it would be. It is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40429</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>You can wear the hood by itself, wear it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40430</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I liked nothing about this dress. The only rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40431</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I work in the wedding industry and have to wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40432 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "0                Home_and_Kitchen_5     5.0    CG   \n",
       "1                Home_and_Kitchen_5     5.0    CG   \n",
       "2                Home_and_Kitchen_5     5.0    CG   \n",
       "3                Home_and_Kitchen_5     1.0    CG   \n",
       "4                Home_and_Kitchen_5     5.0    CG   \n",
       "...                             ...     ...   ...   \n",
       "40427  Clothing_Shoes_and_Jewelry_5     4.0    OR   \n",
       "40428  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "40429  Clothing_Shoes_and_Jewelry_5     2.0    OR   \n",
       "40430  Clothing_Shoes_and_Jewelry_5     1.0    CG   \n",
       "40431  Clothing_Shoes_and_Jewelry_5     5.0    OR   \n",
       "\n",
       "                                                   text_  \n",
       "0      Love this!  Well made, sturdy, and very comfor...  \n",
       "1      love it, a great upgrade from the original.  I...  \n",
       "2      This pillow saved my back. I love the look and...  \n",
       "3      Missing information on how to use it, but it i...  \n",
       "4      Very nice set. Good quality. We have had the s...  \n",
       "...                                                  ...  \n",
       "40427  I had read some reviews saying that this bra r...  \n",
       "40428  I wasn't sure exactly what it would be. It is ...  \n",
       "40429  You can wear the hood by itself, wear it with ...  \n",
       "40430  I liked nothing about this dress. The only rea...  \n",
       "40431  I work in the wedding industry and have to wor...  \n",
       "\n",
       "[40432 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osf = pd.read_csv(\"../../data/fake_reviews_dataset.csv\")\n",
    "print(\"Shape of OFS: \", osf.shape)\n",
    "# osf.head()\n",
    "osf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = BasicTextCleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    osf_cleaned = pd.read_csv(\"../../data/cleaned/osf_cleaned.csv\")\n",
    "    osf_cleaned = osf_cleaned.replace(np.nan, '')\n",
    "except:\n",
    "    osf_cleaned = pd.DataFrame()\n",
    "    osf_cleaned['length'] = osf['text_'].apply(lambda x: len(x))\n",
    "    osf_cleaned['texts'] = cleaner.text_cleaning(osf['text_'])\n",
    "\n",
    "    ordinal = OrdinalEncoder(categories=[['OR', 'CG']], dtype=int)\n",
    "    osf_cleaned['labels'] = ordinal.fit_transform(osf[['label']])\n",
    "    osf_cleaned.to_csv(\"../../data/cleaned/osf_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "class AvgWord2Vec:\n",
    "    def __init__(self, vector_size=300, min_count=1, sg=1, ngram_range=(1, 1), window=5, seed=42):\n",
    "        self.w2v = Word2Vec(vector_size=vector_size, min_count=min_count, sg=sg,\n",
    "                            window=window, workers=5, seed=seed)\n",
    "        self.min_count = min_count\n",
    "        self.sg = sg\n",
    "        self.window = window\n",
    "        self.seed = seed\n",
    "        self.vsize = vector_size\n",
    "\n",
    "        self.ngrams = np.arange(ngram_range[0], ngram_range[1]+1, 1)\n",
    "        self.raw = None\n",
    "        self.corpus = None\n",
    "        self.vocabulary_ = None\n",
    "\n",
    "    def _create_ngrams(self, n, X):\n",
    "        phrases = [list(ngrams(sent.split(), n)) for sent in X]\n",
    "        for i in range(len(phrases)):\n",
    "            phrases[i] = [\" \".join(word) for word in phrases[i]]\n",
    "        return phrases\n",
    "    \n",
    "    def _create_corpus(self, X, update_train=False):\n",
    "        ngrams_phrases = {}\n",
    "        for n in self.ngrams:\n",
    "            phrases = self._create_ngrams(n, X)\n",
    "            ngrams_phrases[f\"{n}\"] = phrases\n",
    "        data = []\n",
    "        corpus = []\n",
    "        for n in ngrams_phrases.values():\n",
    "            if len(data)==0:\n",
    "                data = n\n",
    "            data = [data[i] + n[i] for i in range(len(data))]\n",
    "            corpus.extend(n)\n",
    "        if update_train:\n",
    "            self.corpus = corpus\n",
    "        return data\n",
    "    \n",
    "    def _avg_sentence(self, data):\n",
    "        avg_sentences = []\n",
    "        for sent in data:\n",
    "            if len(sent)!=0:\n",
    "                avg_sentence = np.mean([self.w2v.wv.get_vector(word) for word in sent\n",
    "                                        if word in self.w2v.wv.index_to_key], axis=0)\n",
    "            else:\n",
    "                avg_sentence = np.zeros(self.vsize)\n",
    "            avg_sentences.append(avg_sentence)\n",
    "        return np.array(avg_sentences)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.w2v = Word2Vec(vector_size=self.vsize, min_count=self.min_count, sg=self.sg,\n",
    "                            window=self.window, workers=5, seed=self.seed)\n",
    "        self.raw = list(X)\n",
    "        self._create_corpus(update_train=True, X=X)\n",
    "        self.w2v.build_vocab(self.corpus)\n",
    "        self.w2v.train(self.corpus, total_examples=self.w2v.corpus_count, epochs=self.w2v.epochs)\n",
    "        self.vocabulary_ = self.w2v.wv.key_to_index\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.w2v = Word2Vec(vector_size=self.vsize, min_count=self.min_count, sg=self.sg,\n",
    "                            window=self.window, workers=5, seed=self.seed)\n",
    "        self.raw = list(X)\n",
    "        data = self._create_corpus(update_train=True, X=X)\n",
    "        self.w2v.build_vocab(self.corpus)\n",
    "        self.w2v.train(self.corpus, total_examples=self.w2v.corpus_count, epochs=self.w2v.epochs)\n",
    "        self.vocabulary_ = self.w2v.wv.key_to_index\n",
    "        return scipy.sparse.csr_matrix(self._avg_sentence(data))\n",
    "        \n",
    "    def transform(self, X):\n",
    "        data = self._create_corpus(update_train=False, X=X)\n",
    "        return scipy.sparse.csr_matrix(self._avg_sentence(data))\n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        columns = np.array([f'component_{i+1}' for i in range(self.vsize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(sentences, w2v_model):\n",
    "    avg_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence:\n",
    "            avg_sentence = np.mean([w2v_model.wv.get_vector(word) for word in sentence if word in w2v_model.wv.key_to_index], axis=0)\n",
    "        else:\n",
    "            avg_sentence = np.zeros(w2v_model.vector_size)\n",
    "        avg_sentences.append(avg_sentence)\n",
    "    return np.array(avg_sentences)\n",
    "\n",
    "def text_extractor(X_train, X_test, extractor):\n",
    "    if isinstance(extractor, Word2Vec):\n",
    "        vector_size = extractor.vector_size\n",
    "        window = extractor.window\n",
    "        sg = extractor.sg\n",
    "        extractor = Word2Vec(vector_size=vector_size, sg=sg, window=window, min_count=1, workers=5, seed=42)\n",
    "\n",
    "        cleaner = BasicTextCleaning()\n",
    "        X_train = cleaner.text_cleaning(texts=X_train, methods=['tokenization'])\n",
    "        X_test = cleaner.text_cleaning(texts=X_test, methods=['tokenization'])\n",
    "\n",
    "        extractor.build_vocab(X_train)\n",
    "        extractor.train(X_train, total_examples=extractor.corpus_count, epochs=30)\n",
    "        X_train = avg_word2vec(X_train, extractor)\n",
    "        X_train = pd.DataFrame(X_train, columns=[str(i) for i in range(extractor.vector_size)])\n",
    "        X_test = avg_word2vec(X_test, extractor)\n",
    "        X_test = pd.DataFrame(X_test, columns=[str(i) for i in range(extractor.vector_size)])\n",
    "    else:\n",
    "        X_train = extractor.fit_transform(X_train).toarray()\n",
    "        X_test = extractor.transform(X_test).toarray()\n",
    "        X_train = pd.DataFrame(X_train, columns=extractor.get_feature_names_out())\n",
    "        X_test = pd.DataFrame(X_test, columns=extractor.get_feature_names_out())\n",
    "    \n",
    "    variance = VarianceThreshold()\n",
    "    X_train = variance.fit_transform(X_train)\n",
    "    X_test = variance.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train, columns=variance.get_feature_names_out())\n",
    "    X_test = pd.DataFrame(X_test, columns=variance.get_feature_names_out())\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def text_extractor(X_train, X_test, extractor):\n",
    "    X_train = extractor.fit_transform(X_train).toarray()\n",
    "    X_test = extractor.transform(X_test).toarray()\n",
    "    X_train = pd.DataFrame(X_train, columns=extractor.get_feature_names_out())\n",
    "    X_test = pd.DataFrame(X_test, columns=extractor.get_feature_names_out())\n",
    "    \n",
    "    variance = VarianceThreshold()\n",
    "    X_train = variance.fit_transform(X_train)\n",
    "    X_test = variance.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train, columns=variance.get_feature_names_out())\n",
    "    X_test = pd.DataFrame(X_test, columns=variance.get_feature_names_out())\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def feature_selection(X_train, X_test, selector):\n",
    "    X_train = selector.fit_transform(X_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train, columns=selector.get_feature_names_out())\n",
    "    X_test = pd.DataFrame(X_test, columns=selector.get_feature_names_out())\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(model, X_train, y_train, X_test, probability=True):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if probability:\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        return y_pred, y_pred_proba\n",
    "    return y_pred\n",
    "\n",
    "def evaluation(y_true, y_pred, y_pred_prob, scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc']):\n",
    "    scores = {'accuracy': accuracy_score,\n",
    "              'f1': f1_score,\n",
    "              'recall': recall_score,\n",
    "              'precision': precision_score,\n",
    "              'roc_auc': roc_auc_score}\n",
    "    \n",
    "    result = {}\n",
    "    for method in scoring:\n",
    "        if method == 'roc_auc':\n",
    "            result[method] = scores[method](y_true, y_pred_prob.T[1])\n",
    "        else:\n",
    "            result[method] = scores[method](y_true, y_pred)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, extractor, model=None, selector=None, length_scaler=None,\n",
    "                     scoring=['accuracy', 'f1', 'recall', 'precision', 'roc_auc'], cv=5,\n",
    "                     avg_output=True, quiet=True):\n",
    "    kfolds = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    scores = {method: [] for method in scoring}\n",
    "    round = 1\n",
    "\n",
    "    for train_indices, test_indices in kfolds.split(data.iloc[:, :-1], data.iloc[:, -1]):\n",
    "        train_set, test_set = data.iloc[train_indices, :-1], data.iloc[test_indices, :-1]\n",
    "        y_train, y_test = data.iloc[train_indices, -1], data.iloc[test_indices, -1]\n",
    "\n",
    "        X_train, X_test = text_extractor(X_train=train_set['texts'], X_test=test_set['texts'], extractor=extractor)\n",
    "\n",
    "        if length_scaler is not None:\n",
    "            X_train['length'] = length_scaler.fit_transform(train_set[['length']])\n",
    "            X_test['length'] = length_scaler.transform(test_set[['length']])\n",
    "        \n",
    "        if selector is not None:\n",
    "            X_train, X_test = feature_selection(X_train, X_test, selector)\n",
    "\n",
    "        y_pred, y_pred_prob = modelling(model, X_train, y_train, X_test)\n",
    "\n",
    "        result = evaluation(y_true=y_test, y_pred=y_pred, y_pred_prob=y_pred_prob, scoring=scoring)\n",
    "        for method in scoring:\n",
    "            scores[method].append(result[method])\n",
    "            \n",
    "        if not quiet:\n",
    "            print(f\"round {round}: done\")\n",
    "\n",
    "        round += 1\n",
    "        \n",
    "    if avg_output:\n",
    "        avg_scores = {key: np.mean(values) for key, values in scores.items()}\n",
    "\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractor = AvgWord2Vec(window=2, vector_size=50, seed=42, sg=0)\n",
    "# model = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "# # model = SVC(probability=True, class_weight='balanced')\n",
    "# # extractor = TfidfVectorizer(min_df=0.001, ngram_range=(1, 1))\n",
    "# # model = SVC()\n",
    "\n",
    "# cross_validation(data=osf_cleaned, length_scaler=StandardScaler(),\n",
    "#                  model=model, extractor=extractor, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Testcases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Different Window Sizes\n",
    "<br>\n",
    "Test if window size affect the performance of Word2Vec skipgrams and cbow.\n",
    "\n",
    "* window size range (1, 21, 2)\n",
    "* fixed other components\n",
    "    * no length used nor feature selector\n",
    "    * text Extractor: `AvgWord2Vec(vector_size=100, ngram_range=(1, 1))`\n",
    "    * model: `LogisticRegression(max_iter=1000, class_weight='balanced)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'window': [],\n",
    "          'w2v_type': [],\n",
    "          'accuracy': [],\n",
    "          'f1': [],\n",
    "          'recall': [],\n",
    "          'precision': [],\n",
    "          'roc_auc': []}\n",
    "\n",
    "for sg in [0]:\n",
    "    for window in range(1, 22, 2):\n",
    "        scores = cross_validation(data=osf_cleaned,\n",
    "                                  extractor=AvgWord2Vec(vector_size=100, window=window, sg=sg),\n",
    "                                  model=LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "        output['window'].append(window)\n",
    "        output['w2v_type'].append('cbow' if sg==0 else 'skipgram')\n",
    "        for key, value in scores.items():\n",
    "            output[key].append(value)\n",
    "        print(f\"{output['w2v_type'][-1]} - window {window}: done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df = pd.DataFrame(output)\n",
    "# output_df\n",
    "# output_saved = pd.read_csv(\"../../output/define_testcases/w2v_window_test.csv\")\n",
    "# output_saved\n",
    "# # output_new = pd.concat([output_saved, output_df], axis=0)\n",
    "# # output_new\n",
    "# # output_new.to_csv(\"../../output/define_testcases/w2v_window_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Different Vector Sizes\n",
    "<br>\n",
    "Test if window size affect the performance of Word2Vec skipgrams and cbow.\n",
    "\n",
    "* window size range (1, 21, 2)\n",
    "* fixed other components\n",
    "    * no length used nor feature selector\n",
    "    * text Extractor: `AvgWord2Vec(vector_size=100, ngram_range=(1, 1))`\n",
    "    * model: `LogisticRegression(max_iter=1000, class_weight='balanced)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow - vector 500: done\n",
      "cbow - vector 600: done\n",
      "cbow - vector 700: done\n"
     ]
    }
   ],
   "source": [
    "output = {'vector_size': [],\n",
    "          'w2v_type': [],\n",
    "          'accuracy': [],\n",
    "          'f1': [],\n",
    "          'recall': [],\n",
    "          'precision': [],\n",
    "          'roc_auc': []}\n",
    "\n",
    "for sg in [0]:\n",
    "    for vector in range(500, 800, 100):\n",
    "        scores = cross_validation(data=osf_cleaned,\n",
    "                                  extractor=AvgWord2Vec(vector_size=vector, window=5, sg=sg),\n",
    "                                  model=LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "        output['vector_size'].append(vector)\n",
    "        output['w2v_type'].append('cbow' if sg==0 else 'skipgram')\n",
    "        for key, value in scores.items():\n",
    "            output[key].append(value)\n",
    "        print(f\"{output['w2v_type'][-1]} - vector {vector}: done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df = pd.DataFrame(output)\n",
    "# output_saved = pd.read_csv(\"../../output/define_testcases/w2v_vectorsize_test.csv\")\n",
    "# output_saved\n",
    "# output_new = pd.concat([output_saved, output_df], axis=0)\n",
    "# output_new\n",
    "# output_new.to_csv(\"../../output/define_testcases/w2v_vectorsize_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcases = {'data': {'osf': osf_cleaned},\n",
    "             'length_used': {'None': None},\n",
    "             'feature_extraction': ['Word2Vec(vector_size={}, window={})'],\n",
    "             'feature selection': {'None': None,\n",
    "                                   'PCA': PCA,\n",
    "                                   'SelectKBest(score_func={}, k={})': SelectKBest},\n",
    "             'model': {'LogisticRegression(max_iter=1000, class_weight=\"balanced\")': LogisticRegression(max_iter=1000, class_weight='balanced')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'data': [],\n",
    "          'length_used': [],\n",
    "          'feature_extraction': [],\n",
    "          'feature_selection': [],\n",
    "          'model': [],\n",
    "          'accuracy': [],\n",
    "          'f1': [],\n",
    "          'recall': [],\n",
    "          'precision': [],\n",
    "          'roc_auc': [],\n",
    "          'notes': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = {'data': [],\n",
    "#           'length_used': [],\n",
    "#           'feature_extraction': [],\n",
    "#           'feature_selection': [],\n",
    "#           'model': [],\n",
    "#           'accuracy': [],\n",
    "#           'f1': [],\n",
    "#           'recall': [],\n",
    "#           'precision': [],\n",
    "#           'roc_auc': [],\n",
    "#           'notes': []}\n",
    "\n",
    "# testcases = {'data': {'osf': osf_cleaned},\n",
    "#              'length_used': {'None': None,\n",
    "#                              'StandardScaler': StandardScaler(),\n",
    "#                              'MinMaxScaler': MinMaxScaler()},\n",
    "#              'feature_extraction': ['Word2Vec(vector_size={}, window={})'],\n",
    "#              'feature selection': {'None': None},\n",
    "#              'model': {'LogisticRegression(max_iter=1000, class_weight=\"balanced\")': LogisticRegression(max_iter=1000, class_weight='balanced')}}\n",
    "\n",
    "# for data_name in testcases['data']:\n",
    "#     for length in testcases['length_used']:\n",
    "#         if length == 'None':\n",
    "#             data = testcases['data'][data_name].iloc[:, 1:].copy()\n",
    "#         else:\n",
    "#             data = testcases['data'][data_name].copy()\n",
    "#         for size in np.arange(100, 1100, 100):\n",
    "#             for window in range(3, 9, 2):\n",
    "#                 extractor = Word2Vec(vector_size=size, window=window, workers=5, min_count=1, seed=42)\n",
    "#                 for selector_name in testcases['feature selection']:\n",
    "#                     selector = testcases['feature selection'][selector_name]\n",
    "#                     for model_name in testcases['model']:\n",
    "#                         model = testcases['model'][model_name]\n",
    "#                         scores = cross_validation(data=data,\n",
    "#                                                   length_scaler=testcases['length_used'][length],\n",
    "#                                                   extractor=extractor,\n",
    "#                                                   selector=selector,\n",
    "#                                                   model=model)\n",
    "                        \n",
    "#                         output['data'].append(data_name)\n",
    "#                         output['length_used'].append(length)\n",
    "#                         output['feature_extraction'].append(f'Word2Vec(vector_size={size}, window={window})')\n",
    "#                         output['feature_selection'].append(selector_name)\n",
    "#                         output['model'].append(model_name)\n",
    "#                         for key, values in scores.items():\n",
    "#                             output[key].append(values)\n",
    "\n",
    "output = {'data': [],\n",
    "          'length_used': [],\n",
    "          'feature_extraction': [],\n",
    "          'feature_selection': [],\n",
    "          'model': [],\n",
    "          'accuracy': [],\n",
    "          'f1': [],\n",
    "          'recall': [],\n",
    "          'precision': [],\n",
    "          'roc_auc': [],\n",
    "          'notes': []}\n",
    "\n",
    "testcases = {'data': {'osf': osf_cleaned},\n",
    "             'length_used': {'None': None},\n",
    "             'feature_extraction': ['Word2Vec(vector_size={}, window={})'],\n",
    "             'feature selection': {'None': None},\n",
    "             'model': {'LogisticRegression(max_iter=1000, class_weight=\"balanced\")': LogisticRegression(max_iter=1000, class_weight='balanced')}}\n",
    "\n",
    "for data_name in testcases['data']:\n",
    "    for length in testcases['length_used']:\n",
    "        if length == 'None':\n",
    "            data = testcases['data'][data_name].iloc[:, 1:].copy()\n",
    "        else:\n",
    "            data = testcases['data'][data_name].copy()\n",
    "        for size in np.arange(700, 710, 100):\n",
    "            for window in range(5, 9, 2):\n",
    "                extractor = Word2Vec(vector_size=size, window=window, workers=5, min_count=1, seed=42, sg=1)\n",
    "                for selector_name in testcases['feature selection']:\n",
    "                    selector = testcases['feature selection'][selector_name]\n",
    "                    for model_name in testcases['model']:\n",
    "                        model = testcases['model'][model_name]\n",
    "                        scores = cross_validation(data=data,\n",
    "                                                  length_scaler=testcases['length_used'][length],\n",
    "                                                  extractor=extractor,\n",
    "                                                  selector=selector,\n",
    "                                                  model=model)\n",
    "                        \n",
    "                        output['data'].append(data_name)\n",
    "                        output['length_used'].append(length)\n",
    "                        output['feature_extraction'].append(f'Word2Vec(vector_size={size}, window={window}, sg=1)')\n",
    "                        output['feature_selection'].append(selector_name)\n",
    "                        output['model'].append(model_name)\n",
    "                        for key, values in scores.items():\n",
    "                            output[key].append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_saved = output.copy()\n",
    "output_saved['notes'] = ['']*len(output_saved['data'])\n",
    "# # pd.DataFrame(output_saved).to_csv(\"data/result/test_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>length_used</th>\n",
       "      <th>feature_extraction</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=700, window=5, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.864736</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.861249</td>\n",
       "      <td>0.926651</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=700, window=7, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.863821</td>\n",
       "      <td>0.864472</td>\n",
       "      <td>0.868847</td>\n",
       "      <td>0.860146</td>\n",
       "      <td>0.926498</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data length_used                         feature_extraction  \\\n",
       "0  osf        None  Word2Vec(vector_size=700, window=5, sg=1)   \n",
       "1  osf        None  Word2Vec(vector_size=700, window=7, sg=1)   \n",
       "\n",
       "  feature_selection                                              model  \\\n",
       "0              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "1              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "\n",
       "   accuracy        f1    recall  precision   roc_auc notes  \n",
       "0  0.864736  0.865342  0.869477   0.861249  0.926651        \n",
       "1  0.863821  0.864472  0.868847   0.860146  0.926498        "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_saved_df = pd.DataFrame(output_saved)\n",
    "output_saved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>length_used</th>\n",
       "      <th>feature_extraction</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.842649</td>\n",
       "      <td>0.843850</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.847769</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>0.855068</td>\n",
       "      <td>0.842681</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.849649</td>\n",
       "      <td>0.850687</td>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.844732</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.853635</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.846878</td>\n",
       "      <td>0.915526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.854348</td>\n",
       "      <td>0.855324</td>\n",
       "      <td>0.861271</td>\n",
       "      <td>0.849461</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=600, window=5, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.863796</td>\n",
       "      <td>0.864541</td>\n",
       "      <td>0.869531</td>\n",
       "      <td>0.859616</td>\n",
       "      <td>0.925525</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=600, window=7, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.867322</td>\n",
       "      <td>0.859918</td>\n",
       "      <td>0.924754</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=700, window=3, sg=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.863326</td>\n",
       "      <td>0.864018</td>\n",
       "      <td>0.868673</td>\n",
       "      <td>0.859418</td>\n",
       "      <td>0.925477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=700, window=5, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.864736</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.861249</td>\n",
       "      <td>0.926651</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>osf</td>\n",
       "      <td>None</td>\n",
       "      <td>Word2Vec(vector_size=700, window=7, sg=1)</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.863821</td>\n",
       "      <td>0.864472</td>\n",
       "      <td>0.868847</td>\n",
       "      <td>0.860146</td>\n",
       "      <td>0.926498</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    data length_used                         feature_extraction  \\\n",
       "0    osf         NaN        Word2Vec(vector_size=100, window=3)   \n",
       "1    osf         NaN        Word2Vec(vector_size=100, window=5)   \n",
       "2    osf         NaN        Word2Vec(vector_size=100, window=7)   \n",
       "3    osf         NaN        Word2Vec(vector_size=200, window=3)   \n",
       "4    osf         NaN        Word2Vec(vector_size=200, window=5)   \n",
       "..   ...         ...                                        ...   \n",
       "106  osf         NaN  Word2Vec(vector_size=600, window=5, sg=1)   \n",
       "107  osf         NaN  Word2Vec(vector_size=600, window=7, sg=1)   \n",
       "108  osf         NaN  Word2Vec(vector_size=700, window=3, sg=1)   \n",
       "109  osf        None  Word2Vec(vector_size=700, window=5, sg=1)   \n",
       "110  osf        None  Word2Vec(vector_size=700, window=7, sg=1)   \n",
       "\n",
       "    feature_selection                                              model  \\\n",
       "0                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "1                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "2                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "3                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "4                 NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "..                ...                                                ...   \n",
       "106               NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "107               NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "108               NaN  LogisticRegression(max_iter=1000, class_weight...   \n",
       "109              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "110              None  LogisticRegression(max_iter=1000, class_weight...   \n",
       "\n",
       "     accuracy        f1    recall  precision   roc_auc notes  \n",
       "0    0.842649  0.843850  0.850587   0.837234  0.906563   NaN  \n",
       "1    0.847769  0.848826  0.855068   0.842681  0.911585   NaN  \n",
       "2    0.849649  0.850687  0.856728   0.844732  0.913208   NaN  \n",
       "3    0.852518  0.853635  0.860505   0.846878  0.915526   NaN  \n",
       "4    0.854348  0.855324  0.861271   0.849461  0.917639   NaN  \n",
       "..        ...       ...       ...        ...       ...   ...  \n",
       "106  0.863796  0.864541  0.869531   0.859616  0.925525   NaN  \n",
       "107  0.863029  0.863597  0.867322   0.859918  0.924754   NaN  \n",
       "108  0.863326  0.864018  0.868673   0.859418  0.925477   NaN  \n",
       "109  0.864736  0.865342  0.869477   0.861249  0.926651        \n",
       "110  0.863821  0.864472  0.868847   0.860146  0.926498        \n",
       "\n",
       "[111 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('../../output/csv/word2vec.csv')\n",
    "result = pd.concat([result, output_saved_df], axis=0, ignore_index=True)\n",
    "# result.sort_values(by='accuracy', ascending=True)\n",
    "# result[result['feature_extraction']=='Word2Vec(vector_size=100, window=5)']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv(\"../../output/csv/word2vec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>length_used</th>\n",
       "      <th>feature_extraction</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.842649</td>\n",
       "      <td>0.843850</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.847769</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>0.855068</td>\n",
       "      <td>0.842681</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=100, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.849649</td>\n",
       "      <td>0.850687</td>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.844732</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.853635</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.846878</td>\n",
       "      <td>0.915526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.854348</td>\n",
       "      <td>0.855324</td>\n",
       "      <td>0.861271</td>\n",
       "      <td>0.849461</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=200, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856302</td>\n",
       "      <td>0.857377</td>\n",
       "      <td>0.864039</td>\n",
       "      <td>0.850829</td>\n",
       "      <td>0.918628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=300, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.856623</td>\n",
       "      <td>0.857629</td>\n",
       "      <td>0.863930</td>\n",
       "      <td>0.851424</td>\n",
       "      <td>0.919816</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=300, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.859517</td>\n",
       "      <td>0.860394</td>\n",
       "      <td>0.866098</td>\n",
       "      <td>0.854766</td>\n",
       "      <td>0.921931</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=300, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.859493</td>\n",
       "      <td>0.860598</td>\n",
       "      <td>0.867477</td>\n",
       "      <td>0.853828</td>\n",
       "      <td>0.922632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=400, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.858973</td>\n",
       "      <td>0.859875</td>\n",
       "      <td>0.865743</td>\n",
       "      <td>0.854087</td>\n",
       "      <td>0.921766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=400, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.860704</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>0.867688</td>\n",
       "      <td>0.855668</td>\n",
       "      <td>0.922953</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=400, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.860506</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.867652</td>\n",
       "      <td>0.855393</td>\n",
       "      <td>0.923939</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=500, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.859740</td>\n",
       "      <td>0.860878</td>\n",
       "      <td>0.868183</td>\n",
       "      <td>0.853699</td>\n",
       "      <td>0.922442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=500, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.860754</td>\n",
       "      <td>0.861634</td>\n",
       "      <td>0.867355</td>\n",
       "      <td>0.855993</td>\n",
       "      <td>0.923864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=500, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.862337</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.868957</td>\n",
       "      <td>0.857575</td>\n",
       "      <td>0.924870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=600, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.860789</td>\n",
       "      <td>0.867845</td>\n",
       "      <td>0.853850</td>\n",
       "      <td>0.922766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=600, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.860630</td>\n",
       "      <td>0.861637</td>\n",
       "      <td>0.868096</td>\n",
       "      <td>0.855275</td>\n",
       "      <td>0.923922</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=600, window=7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.862807</td>\n",
       "      <td>0.863743</td>\n",
       "      <td>0.869833</td>\n",
       "      <td>0.857739</td>\n",
       "      <td>0.925050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=700, window=3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.860432</td>\n",
       "      <td>0.861465</td>\n",
       "      <td>0.868094</td>\n",
       "      <td>0.854939</td>\n",
       "      <td>0.922403</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>osf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word2Vec(vector_size=700, window=5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(max_iter=1000, class_weight...</td>\n",
       "      <td>0.860680</td>\n",
       "      <td>0.861683</td>\n",
       "      <td>0.868067</td>\n",
       "      <td>0.855398</td>\n",
       "      <td>0.923877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data length_used                   feature_extraction  feature_selection  \\\n",
       "0   osf         NaN  Word2Vec(vector_size=100, window=3)                NaN   \n",
       "1   osf         NaN  Word2Vec(vector_size=100, window=5)                NaN   \n",
       "2   osf         NaN  Word2Vec(vector_size=100, window=7)                NaN   \n",
       "3   osf         NaN  Word2Vec(vector_size=200, window=3)                NaN   \n",
       "4   osf         NaN  Word2Vec(vector_size=200, window=5)                NaN   \n",
       "5   osf         NaN  Word2Vec(vector_size=200, window=7)                NaN   \n",
       "6   osf         NaN  Word2Vec(vector_size=300, window=3)                NaN   \n",
       "7   osf         NaN  Word2Vec(vector_size=300, window=5)                NaN   \n",
       "8   osf         NaN  Word2Vec(vector_size=300, window=7)                NaN   \n",
       "9   osf         NaN  Word2Vec(vector_size=400, window=3)                NaN   \n",
       "10  osf         NaN  Word2Vec(vector_size=400, window=5)                NaN   \n",
       "11  osf         NaN  Word2Vec(vector_size=400, window=7)                NaN   \n",
       "12  osf         NaN  Word2Vec(vector_size=500, window=3)                NaN   \n",
       "13  osf         NaN  Word2Vec(vector_size=500, window=5)                NaN   \n",
       "14  osf         NaN  Word2Vec(vector_size=500, window=7)                NaN   \n",
       "15  osf         NaN  Word2Vec(vector_size=600, window=3)                NaN   \n",
       "16  osf         NaN  Word2Vec(vector_size=600, window=5)                NaN   \n",
       "17  osf         NaN  Word2Vec(vector_size=600, window=7)                NaN   \n",
       "18  osf         NaN  Word2Vec(vector_size=700, window=3)                NaN   \n",
       "19  osf         NaN  Word2Vec(vector_size=700, window=5)                NaN   \n",
       "\n",
       "                                                model  accuracy        f1  \\\n",
       "0   LogisticRegression(max_iter=1000, class_weight...  0.842649  0.843850   \n",
       "1   LogisticRegression(max_iter=1000, class_weight...  0.847769  0.848826   \n",
       "2   LogisticRegression(max_iter=1000, class_weight...  0.849649  0.850687   \n",
       "3   LogisticRegression(max_iter=1000, class_weight...  0.852518  0.853635   \n",
       "4   LogisticRegression(max_iter=1000, class_weight...  0.854348  0.855324   \n",
       "5   LogisticRegression(max_iter=1000, class_weight...  0.856302  0.857377   \n",
       "6   LogisticRegression(max_iter=1000, class_weight...  0.856623  0.857629   \n",
       "7   LogisticRegression(max_iter=1000, class_weight...  0.859517  0.860394   \n",
       "8   LogisticRegression(max_iter=1000, class_weight...  0.859493  0.860598   \n",
       "9   LogisticRegression(max_iter=1000, class_weight...  0.858973  0.859875   \n",
       "10  LogisticRegression(max_iter=1000, class_weight...  0.860704  0.861635   \n",
       "11  LogisticRegression(max_iter=1000, class_weight...  0.860506  0.861472   \n",
       "12  LogisticRegression(max_iter=1000, class_weight...  0.859740  0.860878   \n",
       "13  LogisticRegression(max_iter=1000, class_weight...  0.860754  0.861634   \n",
       "14  LogisticRegression(max_iter=1000, class_weight...  0.862337  0.863226   \n",
       "15  LogisticRegression(max_iter=1000, class_weight...  0.859690  0.860789   \n",
       "16  LogisticRegression(max_iter=1000, class_weight...  0.860630  0.861637   \n",
       "17  LogisticRegression(max_iter=1000, class_weight...  0.862807  0.863743   \n",
       "18  LogisticRegression(max_iter=1000, class_weight...  0.860432  0.861465   \n",
       "19  LogisticRegression(max_iter=1000, class_weight...  0.860680  0.861683   \n",
       "\n",
       "      recall  precision   roc_auc  notes  \n",
       "0   0.850587   0.837234  0.906563    NaN  \n",
       "1   0.855068   0.842681  0.911585    NaN  \n",
       "2   0.856728   0.844732  0.913208    NaN  \n",
       "3   0.860505   0.846878  0.915526    NaN  \n",
       "4   0.861271   0.849461  0.917639    NaN  \n",
       "5   0.864039   0.850829  0.918628    NaN  \n",
       "6   0.863930   0.851424  0.919816    NaN  \n",
       "7   0.866098   0.854766  0.921931    NaN  \n",
       "8   0.867477   0.853828  0.922632    NaN  \n",
       "9   0.865743   0.854087  0.921766    NaN  \n",
       "10  0.867688   0.855668  0.922953    NaN  \n",
       "11  0.867652   0.855393  0.923939    NaN  \n",
       "12  0.868183   0.853699  0.922442    NaN  \n",
       "13  0.867355   0.855993  0.923864    NaN  \n",
       "14  0.868957   0.857575  0.924870    NaN  \n",
       "15  0.867845   0.853850  0.922766    NaN  \n",
       "16  0.868096   0.855275  0.923922    NaN  \n",
       "17  0.869833   0.857739  0.925050    NaN  \n",
       "18  0.868094   0.854939  0.922403    NaN  \n",
       "19  0.868067   0.855398  0.923877    NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(r\"../../output/csv/word2vec.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
